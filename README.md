ä¸‹é¢æ˜¯**æ•´åˆåŽçš„å®Œæ•´ README.mdï¼ˆæœ€ç»ˆç‰ˆï¼‰**ï¼Œå·²ç»**æŒ‰ä½ çš„è¦æ±‚**æŠŠ
ðŸ‘‰ **`BBC_DL/checkpoints/*.pth` çš„ç”Ÿæˆè¯´æ˜Žç´§è·Ÿåœ¨ `train` å‘½ä»¤åŽé¢**ï¼Œé€»è¾‘æ¸…æ¥šã€TA/è¯»è€…ä¸€çœ¼å°±æ‡‚ï¼Œå¯ç›´æŽ¥æ•´ä½“æ›¿æ¢ä½ çŽ°åœ¨çš„ READMEã€‚

---

# NLPpj1: ML, DL, and BERT for BBC News Text Classification

## Overview

This project presents a **comparative study of text classification methods** on the **BBC News dataset**, covering three major paradigms in Natural Language Processing:

* **Traditional Machine Learning**
  Bag-of-Words (BoW) / TF-IDF with classical classifiers
* **Deep Learning**
  Word2Vec-based neural networks
* **Transformer-based Models**
  BERT fine-tuning

The task is formulated as a **5-class multi-class text classification problem**, aiming to systematically analyze performance differences across different model families.

---

## Project Structure

```text
.
â”œâ”€â”€ BBC_txt_Cls/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ bow/
â”‚   â””â”€â”€ tfidf/
â”‚   Traditional machine learning baselines
â”‚   (BoW / TF-IDF + classical classifiers)
â”‚
â”œâ”€â”€ BBC_DL/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ outputs/
â”‚   Deep learning models with Word2Vec embeddings
â”‚   (ANN / CNN / RNN / LSTM)
â”‚
â”œâ”€â”€ BBC_Bert/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ bertviz_repo/
â”‚   Transformer-based model using BERT
â”‚   (fine-tuning, evaluation, visualization)
â”‚
â”œâ”€â”€ result/
â”‚   Aggregated evaluation metrics (JSON files)
â”‚
â”œâ”€â”€ data/
â”‚   Dataset files (user-provided, optional)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Environment Setup

It is recommended to create and activate a clean Python environment before running the experiments.

```bash
conda create -n nlp python=3.10 -y
conda activate nlp
pip install -r requirements.txt
```

---

## How to Run

### 1. Traditional Machine Learning (BoW / TF-IDF)

Run all traditional machine learning baselines, including:

* Logistic Regression
* Linear SVM
* Naive Bayes
* Random Forest

```bash
cd BBC_txt_Cls
python -m src.run_ml
```

**Output examples**

```text
bow/linear_svm_metrics.json
bow/logistic_regression_metrics.json
bow/naive_bayes_metrics.json
bow/random_forest_metrics.json
tfidf/linear_svm_metrics.json
tfidf/logistic_regression_metrics.json
tfidf/naive_bayes_metrics.json
tfidf/random_forest_metrics.json
```

Each JSON file contains:

* Accuracy
* Macro Precision / Recall / F1-score
* AUC
* Confusion Matrix

---

### 2. Deep Learning (Word2Vec + ANN / CNN / RNN / LSTM)

Deep learning models are trained using **Word2Vec embeddings**.

```bash
cd BBC_DL
```

#### Training

```bash
python -m src.train --model ann
```

After training, the **best-performing model checkpoint** is **automatically saved** to:

```text
BBC_DL/checkpoints/best_ann.pth
```

Available model options and corresponding checkpoints:

* `ann`  â†’ `best_ann.pth`
* `cnn`  â†’ `best_cnn.pth`
* `rnn`  â†’ `best_rnn.pth`
* `lstm` â†’ `best_lstm.pth`

> The checkpoint is saved automatically during training based on validation performance.

#### Evaluation

```bash
python -m src.evaluate --model ann
```

Evaluation metrics and confusion matrices are saved as JSON files in:

```text
BBC_DL/outputs/
```

**Example DL results (ANN)**

* Accuracy: **0.9506**
* Macro Precision / Recall / F1: **0.9505 / 0.9511 / 0.9500**
* AUC: **0.9964**

---

### 3. Transformer-Based Model (BERT)

Fine-tune and evaluate a **BERT-based classifier** on the BBC News dataset.

```bash
cd BBC_Bert
```

#### Training

```bash
python -m src.train
```

After training, the **best BERT checkpoint** is automatically saved to:

```text
BBC_Bert/checkpoints/best_bert.pth
```

#### Evaluation

```bash
python -m src.evaluate
```

Main evaluation output:

```text
eval_bert.json
```

**Example BERT results**

* Loss: **0.0673**
* Accuracy: **0.9820**
* Macro Precision / Recall / F1: **0.9823 / 0.9820 / 0.9821**
* AUC: **0.9995**

---

## Evaluation Metrics

All models are evaluated using:

* Accuracy
* Macro-averaged Precision
* Macro-averaged Recall
* Macro-averaged F1-score
* AUC
* Confusion Matrix

---

## Dataset

BBC News Dataset (Kaggle):

[https://www.kaggle.com/datasets/hgultekin/bbcnewsarchive](https://www.kaggle.com/datasets/hgultekin/bbcnewsarchive)

> The dataset is **not included** in this repository.
> Please download it manually and place it under `data/`, or modify dataset paths accordingly.

---

## Model Checkpoints (`.pth` Files)

* Model checkpoints are **generated automatically during training**.
* `.pth` files are **not tracked by Git** and are **excluded from GitHub**.
* To reproduce results, users should re-run the training scripts locally.
* Checkpoints are only required for inference or evaluation without retraining.

---

## Reproducibility Notes

* Ensure consistent dataset paths and preprocessing across ML, DL, and BERT modules.
* Random seeds can be fixed in training scripts for reproducibility.
* Datasets and checkpoints are intentionally excluded from version control following standard ML research practices.

